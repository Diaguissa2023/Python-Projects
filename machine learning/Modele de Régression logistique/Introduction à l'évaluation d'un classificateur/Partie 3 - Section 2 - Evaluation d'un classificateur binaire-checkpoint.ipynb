{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation d'un classificateur binaire: Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction aux données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Lire le fichier admissions.csv, créer un modèle de régression logistique et l'adapter aux données d'entrainement.\n",
    "+ Appliquer la méthode predict() sur le modèle pour retourner le libellé pour chaque observation dans le dataset admissions. Assigner la liste résultante à la variable labels.\n",
    "+ Ajouter une nouvelle colonne au DataFrame admissions qu'on nommera predicted_label qui contient les valeurs de la liste labels.\n",
    "+ Afficher la distribution des valeurs de la colonne predicted_label.\n",
    "+ Afficher les 5 premières lignes du DataFrame admissions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    598\n",
      "1     46\n",
      "Name: predicted_label, dtype: int64\n",
      "   admit       gpa         gre  predicted_label\n",
      "0      0  3.177277  594.102992                0\n",
      "1      0  3.412655  631.528607                0\n",
      "2      0  2.728097  553.714399                0\n",
      "3      0  3.093559  551.089985                0\n",
      "4      0  3.141923  537.184894                0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "admissions = pd.read_csv('admissions.csv')\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(admissions[['gpa']], admissions['admit'])\n",
    "\n",
    "labels = model.predict(admissions[['gpa']])\n",
    "admissions['predicted_label'] = labels\n",
    "\n",
    "print(admissions['predicted_label'].value_counts())\n",
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Précision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Renommer la colonne admit du DataFrame admissions en actual_label afin d'indiquer plus clairement quelle colonne contient les libellés prédits (predicted_label) et quelle colonne contient les libellés réels (actual_label).\n",
    "+ Comparer la colonne predicted_label avec la colonne actual_label.\n",
    " - Utiliser un double signe égal  (==) pour comparer les 2 objets Series et assigner l'objet Series résultant à la variable matches.\n",
    "+ Utiliser la filtrage conditionnel pour filtrer le DataFrame admissions uniquement sur les lignes où matches vaut True. Assigner le DataFrame résultant à la variable correct_predictions.\n",
    " - Afficher les 5 premières lignes de correct_predictions pour vous assurer que les valeurs des colonnes predicted_label et actual_label sont égales.\n",
    "+ Calculer la précision et affecter la valeur résultante à la variable accuracy.\n",
    " - Afficher le résultat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit       gpa         gre  predicted_label  actual_label\n",
      "0      0  3.177277  594.102992                0             0\n",
      "1      0  3.412655  631.528607                0             0\n",
      "2      0  2.728097  553.714399                0             0\n",
      "3      0  3.093559  551.089985                0             0\n",
      "4      0  3.141923  537.184894                0             0\n"
     ]
    }
   ],
   "source": [
    "admissions['actual_label'] = admissions['admit']\n",
    "matches = admissions['predicted_label'] == admissions['actual_label']\n",
    "correct_predictions = admissions[matches]\n",
    "print(correct_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6459627329192547\n"
     ]
    }
   ],
   "source": [
    "accuracy = len(correct_predictions) / len(admissions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats de la classification binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Extraire toutes les lignes pour lesquelles la valeur de 'predicted_label' et de actual_label sont égales à 1. Ensuite calculer le nombre de Vrais positifs et assigner le résultat à la variable true_positives.\n",
    "+ Extraire toutes les lignes pour lesquelles la valeur de 'predicted_label' de actual_label sont égales à  0. Ensuite calculer le nombre de Vrais négatifs et assigner le résultat à la variable true_negatives.\n",
    "+ Afficher les résultats true_positives et true_negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "385\n"
     ]
    }
   ],
   "source": [
    "true_positive_filter = (admissions['predicted_label'] == 1) & (admissions['actual_label'] == 1)\n",
    "true_positives = len(admissions[true_positive_filter])\n",
    "\n",
    "true_negatives_filter = (admissions['predicted_label'] == 0) & (admissions['actual_label'] == 0)\n",
    "true_negatives = len(admissions[true_negatives_filter])\n",
    "\n",
    "print(true_positives)\n",
    "print(true_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensibilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Calculer le nombre de Faux Positifs (c’est-à-dire où le modèle a prédit un rejet alors que l'étudiant a été admis)et assigner le résultat à la variable false_negatives.\n",
    "+ Calculer la sensibilité et assigner le résultat à la variable sensitivity.\n",
    "+ Afficher le résultat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12704918032786885\n"
     ]
    }
   ],
   "source": [
    "true_positive_filter = (admissions[\"predicted_label\"] == 1) & (admissions[\"actual_label\"] == 1)\n",
    "true_positives = len(admissions[true_positive_filter])\n",
    "\n",
    "false_negative_filter = (admissions['predicted_label'] == 0) & (admissions['actual_label'] == 1)\n",
    "false_negatives = len(admissions[false_negative_filter])\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spécificité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Calculer le nombre de Faux Positifs (c’est-à-dire où le modèle à prédit des admissions mais les étudiants ont au final été rejetés) et assigner le résultat à la variable false_positives.\n",
    "+ Calculer la spécificité et assigner le résultat à la variable specificity.\n",
    "+ Afficher le résultat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625\n"
     ]
    }
   ],
   "source": [
    "true_negative_filter = (admissions[\"predicted_label\"] == 0) & (admissions[\"actual_label\"] ==\n",
    "                                                               0)\n",
    "true_negatives = len(admissions[true_negative_filter])\n",
    "\n",
    "false_positive_filter = (admissions['predicted_label'] == 1) & (admissions['actual_label'] == 0)\n",
    "false_positives = len(admissions[false_positive_filter])\n",
    "\n",
    "specificity = (true_negatives) / (false_positives + true_negatives)\n",
    "print(specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
